{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f382c1c3-5f76-4754-9bf4-90513a14993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sentence_transformers import SentenceTransformer   # if you use SciBERT\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from math import ceil\n",
    "\n",
    "import joblib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    HistGradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    hamming_loss,\n",
    "    make_scorer,\n",
    "    precision_recall_fscore_support,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    ParameterGrid,\n",
    "    RandomizedSearchCV,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3f947-fac0-4c8a-a3c7-e1e68e356940",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7966f8a2-7095-47ea-b0f9-09599458cd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenotype</th>\n",
       "      <th>phen_data</th>\n",
       "      <th>morph</th>\n",
       "      <th>quant_morph</th>\n",
       "      <th>qual_morph</th>\n",
       "      <th>color_pattern</th>\n",
       "      <th>shape</th>\n",
       "      <th>texture</th>\n",
       "      <th>ultrastruct</th>\n",
       "      <th>interbr_morph</th>\n",
       "      <th>...</th>\n",
       "      <th>nomenclat_history</th>\n",
       "      <th>biogeo</th>\n",
       "      <th>id</th>\n",
       "      <th>displayed_text</th>\n",
       "      <th>checked</th>\n",
       "      <th>sequencing</th>\n",
       "      <th>batch</th>\n",
       "      <th>not important</th>\n",
       "      <th>is_random</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./Corpus/EJT/10_5852_ejt_2021_735_1243.json_0</td>\n",
       "      <td>The material examined was collected in fragmen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>batch1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>./Corpus/EJT/10_5852_ejt_2021_735_1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./Corpus/Zootaxa/1/zootaxa_1920_1_5.json_0</td>\n",
       "      <td>Invertebrate samples\\nwere collected using a h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>batch1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>./Corpus/Zootaxa/1/zootaxa_1920_1_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   phenotype  phen_data  morph  quant_morph  qual_morph  color_pattern  shape  \\\n",
       "0          1          1      1            1           0              0      0   \n",
       "1          1          0      0            0           0              0      0   \n",
       "\n",
       "   texture  ultrastruct  interbr_morph  ...  nomenclat_history  biogeo  \\\n",
       "0        0            0              0  ...                  0       0   \n",
       "1        0            0              0  ...                  0       0   \n",
       "\n",
       "                                              id  \\\n",
       "0  ./Corpus/EJT/10_5852_ejt_2021_735_1243.json_0   \n",
       "1     ./Corpus/Zootaxa/1/zootaxa_1920_1_5.json_0   \n",
       "\n",
       "                                      displayed_text  checked  sequencing  \\\n",
       "0  The material examined was collected in fragmen...        0           0   \n",
       "1  Invertebrate samples\\nwere collected using a h...        0           0   \n",
       "\n",
       "    batch  not important  is_random                                paper_id  \n",
       "0  batch1            NaN          1  ./Corpus/EJT/10_5852_ejt_2021_735_1243  \n",
       "1  batch1            NaN          1     ./Corpus/Zootaxa/1/zootaxa_1920_1_5  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\conix\\Dropbox\\FNRS project taxonomy\\methods in taxonomy\\coding_trial\\testData13052025.csv\")\n",
    "df = df.drop(columns = 'Unnamed: 0')\n",
    "\n",
    "\n",
    "# add a column for which data was really randomly sampled\n",
    "# this avoid testing on oversampled sparse classes\n",
    "\n",
    "df['is_random'] = np.where(df.batch.isin(['batch1', 'batch2_m', 'batch2_s', 'batch2_l', 'batch2_j',\n",
    "       'batch3_l']),1,0)\n",
    "df['paper_id'] = [i.split(\".json\")[0] for i in df.id.values]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78911c5a-287e-4bb1-b702-5d722c952337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list with categories of interest\n",
    "filename = r\"C:\\Users\\conix\\Dropbox\\FNRS project taxonomy\\methods in taxonomy\\data\\categories_of_interest.txt\"\n",
    "with open(filename, 'r') as file:\n",
    "    cats = json.load(file)\n",
    "\n",
    "# load the dictionary to map category column names to gpt names\n",
    "filename = r'C:\\\\Users\\\\conix\\\\Dropbox\\\\FNRS project taxonomy\\\\methods in taxonomy\\\\data\\\\category_names_dict.txt'\n",
    "with open(filename, 'r') as file:\n",
    "    category_names = json.load(file)\n",
    "\n",
    "# descriptions of the various categories, used in the first try with gpt4omini\n",
    "filename = r'C:\\\\Users\\\\conix\\\\Dropbox\\\\FNRS project taxonomy\\\\methods in taxonomy\\\\data\\\\methods_description_gpt4omini_first_try.txt'\n",
    "with open(filename, 'r') as file:\n",
    "    methods_old = json.load(file)\n",
    "\n",
    "# descriptions of the various categories, used in the second try with gpt4omini\n",
    "filename = r'C:\\\\Users\\\\conix\\\\Dropbox\\\\FNRS project taxonomy\\\\methods in taxonomy\\\\data\\\\methods_description_gpt4omini_second_try.txt'\n",
    "with open(filename, 'r') as file:\n",
    "    methods = json.load(file)\n",
    "\n",
    "# hierarchical classification of the categories\n",
    "filename = r\"C:\\Users\\conix\\Dropbox\\FNRS project taxonomy\\methods in taxonomy\\data\\classification_categories.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "    classif = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b51905b-0418-4ad0-9fc5-f29ef3b11149",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_df   = df[df['is_random'] == 1]      # unbiased rows\n",
    "biased_df = df[df['is_random'] == 0]      # rows from biased sampling (to increase sparse categories)\n",
    "\n",
    "X_rand, y_rand = rand_df['displayed_text'], rand_df[cats]\n",
    "X_bias, y_bias = biased_df['displayed_text'], biased_df[cats]\n",
    "\n",
    "# take 80/20 split from the unbiased part\n",
    "# use this for training, not for validation or testing\n",
    "# the biased samples are only used for training, i.e. appended to the training data within each fold's training set\n",
    "# at the final retraining, the biased samples are also used for training\n",
    "msss = MultilabelStratifiedShuffleSplit(test_size=0.20, random_state=42)\n",
    "train_idx, test_idx = next(msss.split(X_rand, y_rand))\n",
    "\n",
    "X_train_raw, y_train_raw = X_rand.iloc[train_idx], y_rand.iloc[train_idx]\n",
    "X_test,      y_test      = X_rand.iloc[test_idx],  y_rand.iloc[test_idx]\n",
    "\n",
    "class_frequencies = y_train_raw.sum(axis=0).values\n",
    "\n",
    "\n",
    "# features & pipeline skeleton—unchanged\n",
    "tfidf  = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95,\n",
    "                         sublinear_tf=True, norm='l2', dtype=np.float32,\n",
    "                         lowercase=True, strip_accents='unicode')\n",
    "\n",
    "# for estimators that don't accept sparse matrices (rf, knn, gb)\n",
    "densify = FunctionTransformer(lambda x: x.toarray(), accept_sparse=True)\n",
    "\n",
    "# we choose macro_F1 as our classes are very imbalanced, and many are very sparse\n",
    "score   = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# use multilabelstratifiedkfold to keep the label proportions roughly equal\n",
    "# 5 folds in the outer loop (for model evaluation)\n",
    "outer = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# 5 folds in the inner loop (for hyperparameter tuning)\n",
    "inner = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b193032-fa83-4507-a50f-29ec8dfc9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data for upload\n",
    "\n",
    "upload_data_lr = {'training data':{'X_train_combined': pd.concat([X_train_raw, X_bias]), 'y_train_combined':pd.concat([y_train_raw, y_bias]), 'X_train_raw':X_train_raw, 'X_bias':X_bias, 'y_train_raw':y_train_raw, 'y_bias':y_bias, 'train_idx':train_idx},\n",
    "              'test data':{'X_test':X_test, 'y_test':y_test, 'test_idx':test_idx}, \n",
    "              'og_data': df,\n",
    "              'class_frequencies':class_frequencies,\n",
    "               'labels':cats\n",
    "              }\n",
    "\n",
    "with open(\"methods_paper_files/upload_data_lr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(upload_data_lr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bb27de-550e-4c58-af47-f9a8ae7cb452",
   "metadata": {},
   "source": [
    "To make it computationally feasible, but also tune all hyperparameters, we'll go in different steps:\n",
    "1) choose a feature family, using standard LR hyperparameters.\n",
    "2) tune the chosen feature family, using standard LR hyperparameters.\n",
    "3) tune LR, using the chosen feature family.\n",
    "\n",
    "We also tune thresholds, but that's part of the nested CV. This is done by storing the probabilities, and using the held out validation set to tune thresholds. This way, there is no real leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba44b3-2474-427d-b006-db9cdbb37b9a",
   "metadata": {},
   "source": [
    "# STEP 1: Select a feature family\n",
    "\n",
    "In the CompareCLassifiers notebook, we chose between various classic ML models and chose LR. For that, we used a standard feature configuration. Now that we've chosen LR, we'll do CV to find the best feature family for our job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f31ff-1bfc-4254-bf5b-be7a8aedbea5",
   "metadata": {},
   "source": [
    "## helper functions for nested cv\n",
    "\n",
    "Instead of using a validation set, we do nested cross validation. We start by writing helper functions for running it, as we'll need it in all three steps of our approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cebe6ee1-99d6-4c8f-9a4c-e1e170436a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics for reporting and validation\n",
    "def fold_metrics(y_true, y_pred):\n",
    "    \"\"\"Return overall + per-label metrics in a flat dict.\"\"\"\n",
    "    out = {\n",
    "        'macro_f1'  : f1_score(y_true, y_pred, average='macro'),\n",
    "        'micro_f1'  : f1_score(y_true, y_pred, average='micro'),\n",
    "        'macro_prec': precision_score(y_true, y_pred, average='macro'),\n",
    "        'micro_prec': precision_score(y_true, y_pred, average='micro'),\n",
    "        'macro_rec' : recall_score(y_true, y_pred, average='macro'),\n",
    "        'micro_rec' : recall_score(y_true, y_pred, average='micro'),\n",
    "        'hamming'   : hamming_loss(y_true, y_pred),\n",
    "        'subset_acc': accuracy_score(y_true, y_pred),\n",
    "    }\n",
    "    p, r, f, s = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0)\n",
    "    for i, lab in enumerate(y_true.columns):\n",
    "        out[f'{lab}_prec'] = p[i]\n",
    "        out[f'{lab}_rec']  = r[i]\n",
    "        out[f'{lab}_f1']   = f[i]\n",
    "        out[f'{lab}_sup']  = s[i]\n",
    "    return out\n",
    "\n",
    "# function to run nested cross validation\n",
    "# we'll need this function in various steps\n",
    "\n",
    "def cv_with_stats(pipe, grid, thresh_grid=np.arange(0.20, 0.81, 0.0125)):\n",
    "    outer_oof   = np.zeros((len(X_train_raw), len(cats)), dtype=np.float32)\n",
    "    outer_truth = y_train_raw.values.copy()\n",
    "    scores, best_params = [], []\n",
    "\n",
    "    # wrap the generator in tqdm → one tick per fold\n",
    "    for fold, (train_idx, val_idx) in enumerate(\n",
    "            tqdm(outer.split(X_train_raw, y_train_raw),\n",
    "                 total=outer.get_n_splits(), desc=\"Outer CV\"), 1):\n",
    "\n",
    "        X_tr = pd.concat([X_train_raw.iloc[train_idx], X_bias])\n",
    "        y_tr = pd.concat([y_train_raw.iloc[train_idx], y_bias])\n",
    "        X_val, y_val = X_train_raw.iloc[val_idx], y_train_raw.iloc[val_idx]\n",
    "\n",
    "        tuner = GridSearchCV(pipe, grid, scoring=score, cv=inner,\n",
    "                             n_jobs=-1, verbose=0)\n",
    "        tuner.fit(X_tr, y_tr)\n",
    "        best_params.append(tuner.best_params_)\n",
    "\n",
    "        outer_oof[val_idx, :] = tuner.predict_proba(X_val)\n",
    "\n",
    "        fold_pred = (outer_oof[val_idx] >= 0.5).astype(int)\n",
    "        scores.append(fold_metrics(y_val, fold_pred))\n",
    "\n",
    "    # pooled threshold search (unchanged) …\n",
    "    thresholds = []\n",
    "    for j in range(outer_oof.shape[1]):\n",
    "        best_f1, best_thr = -1.0, 0.5\n",
    "        y_true = outer_truth[:, j]\n",
    "        for thr in thresh_grid:\n",
    "            y_bin = (outer_oof[:, j] >= thr)\n",
    "            f1    = f1_score(y_true, y_bin, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_thr = f1, thr\n",
    "        thresholds.append(best_thr)\n",
    "\n",
    "    df_scores = pd.DataFrame(scores)\n",
    "    return {\n",
    "        \"mean\"      : df_scores.mean(),\n",
    "        \"std\"       : df_scores.std(ddof=1),\n",
    "        \"ci_95\"     : df_scores.quantile([0.025, 0.975]),\n",
    "        \"fold_df\"   : df_scores,\n",
    "        \"best_params\": best_params,\n",
    "        \"thresholds\": thresholds,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651ded4-1803-4425-90c9-9e7301cf520d",
   "metadata": {},
   "source": [
    "## Feature families\n",
    "\n",
    "We'll try scibert, plain tf-idf, character and word tf-idf, and tf-idf combined with dimensionality reduction via truncated SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e5e2bb0-a082-4622-b62f-3a51bb78e5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05809721a70348619b5bb46e63629e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# precompute the scibert embeddings\n",
    "\n",
    "sbert = SentenceTransformer(\n",
    "    'jordyvl/scibert_scivocab_uncased_sentence_transformer'\n",
    ")\n",
    "\n",
    "# encode all texts in one go\n",
    "texts = df['displayed_text'].tolist()\n",
    "all_embs = sbert.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "np.save('methods_paper_files/sciBERT_embs.npy', all_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ba40675-30fd-406f-91eb-2c5c0caa4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embeddings and define a function to use them\n",
    "\n",
    "all_embs = np.load('methods_paper_files/sciBERT_embs.npy')\n",
    "\n",
    "# a lookup transformer that pulls rows by index\n",
    "def emb_lookup(X):\n",
    "    return all_embs[X]\n",
    "\n",
    "sbert_lookup = FunctionTransformer(func=lambda inds: emb_lookup(inds), validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea489029-572c-436a-985a-c5646ac7021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature and minimal lr grid\n",
    "\n",
    "feature_grid = {\n",
    "    'sciBERT': Pipeline([\n",
    "    # 1-D array of indices, not a 2-D column\n",
    "    ('idx', FunctionTransformer(lambda X: X.index.values, validate=False)),\n",
    "    ('emb', sbert_lookup)\n",
    "]),\n",
    "    'plain_12': TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95,\n",
    "                                sublinear_tf=True, norm='l2'),\n",
    "    'char_union': FeatureUnion([\n",
    "        ('word', TfidfVectorizer(ngram_range=(1,2), min_df=2)),\n",
    "        ('char', TfidfVectorizer(analyzer='char', ngram_range=(3,5), min_df=2))\n",
    "    ]),\n",
    "    'lsa_300': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1,2), min_df=2)),\n",
    "        ('svd', TruncatedSVD(300, random_state=42))\n",
    "    ])\n",
    "    \n",
    "}\n",
    "\n",
    "# we will tune these parameters later.\n",
    "# just a minimal grid now to make sure we give all feature families a fair chance\n",
    "\n",
    "param_grid = {\n",
    "    'clf__estimator__C':            [0.01, 0.1, 1, 10],\n",
    "    'clf__estimator__class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1189877-d56a-44e1-8c31-9065567fbdcf",
   "metadata": {},
   "source": [
    "## Compare feature families using gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4876dc2d-e0da-49a9-ac77-8a7c57536544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature sets: 100%|███████████████████████████████████████████████████████████████████| 4/4 [1:06:07<00:00, 991.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature-set comparison (tuned LR on each family):\n",
      "             macro_f1  micro_f1\n",
      "plain_12    0.718778  0.817916\n",
      "char_union  0.711081  0.814621\n",
      "lsa_300     0.705863  0.801031\n",
      "sciBERT     0.664533  0.771111\n",
      "\n",
      "Best feature configuration: plain_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feature_results = {}   # mean metrics per family\n",
    "feature_folds   = {}   # n_folds×metrics DataFrame per family\n",
    "feature_best_params = {}\n",
    "\n",
    "for name, vect in tqdm(feature_grid.items(), desc=\"Feature sets\"):\n",
    "    pipe = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf',  OneVsRestClassifier(\n",
    "                    LogisticRegression(max_iter=2000, solver='lbfgs')\n",
    "                ))\n",
    "    ])\n",
    "    # now pass the grid so LR is tuned for *this* representation\n",
    "    res = cv_with_stats(pipe, param_grid)\n",
    "    \n",
    "    feature_folds[name]   = res['fold_df']   # 5 outer-fold rows\n",
    "    feature_results[name] = res['mean']      # mean across folds\n",
    "    feature_best_params[name] = res['best_params']\n",
    "\n",
    "\n",
    "feat_df = (\n",
    "    pd.DataFrame(feature_results)\n",
    "      .T.sort_values('macro_f1', ascending=False)\n",
    "      [['macro_f1', 'micro_f1']]\n",
    ")\n",
    "print(\"\\nFeature-set comparison (tuned LR on each family):\\n\", feat_df)\n",
    "\n",
    "best_feat_name = feat_df.index[0]\n",
    "BEST_FEATURE_PIPE = feature_grid[best_feat_name]\n",
    "print(f\"\\nBest feature configuration: {best_feat_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa6ac667-a49c-42cf-ad2e-a750b011b00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paired bootstrap tests vs plain_12 :\n",
      "         vs  Δ mean(F1)  CI_low  CI_high  p_two-sided\n",
      "   sciBERT       0.054   0.048    0.059        0.000\n",
      "char_union       0.008   0.003    0.016        0.000\n",
      "   lsa_300       0.013  -0.003    0.027        0.122\n"
     ]
    }
   ],
   "source": [
    "# build a 5×4 table of macro-F1\n",
    "macro_scores = pd.DataFrame({\n",
    "    name: df['macro_f1'].values\n",
    "    for name, df in feature_folds.items()\n",
    "})\n",
    "\n",
    "# plot means ±95% CI\n",
    "n = len(macro_scores)\n",
    "means = macro_scores.mean()\n",
    "ses   = macro_scores.std(ddof=1) / np.sqrt(n)\n",
    "cis   = ses * t.ppf(0.975, df=n-1)\n",
    "\n",
    "ax = means.plot(kind='bar', yerr=cis, capsize=4, figsize=(6,4))\n",
    "ax.set_ylabel(\"Macro-F1\"); ax.set_title(\"Feature family comparison\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# paired bootstrap vs best\n",
    "best = means.idxmax()\n",
    "comparisons = []\n",
    "B = 5000\n",
    "for fam in macro_scores.columns:\n",
    "    if fam == best: continue\n",
    "    diff = macro_scores[best] - macro_scores[fam]\n",
    "    boots = np.random.choice(diff, (B, len(diff)), replace=True).mean(axis=1)\n",
    "    lo, hi = np.percentile(boots, [2.5, 97.5])\n",
    "    p = (np.mean(boots < 0) if diff.mean()>0 else np.mean(boots>0))*2\n",
    "    comparisons.append({\n",
    "        'vs': fam,\n",
    "        'Δ mean(F1)': diff.mean(),\n",
    "        'CI_low': lo, 'CI_high': hi,\n",
    "        'p_two-sided': p\n",
    "    })\n",
    "comp_df = pd.DataFrame(comparisons).round(3)\n",
    "print(\"\\nPaired bootstrap tests vs\", best, \":\\n\", comp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e0186-0a82-415f-9b72-019858c96b1e",
   "metadata": {},
   "source": [
    "# Step 2: Tune TF-IDF\n",
    "\n",
    "Now that we know TF-IDF is best, we further tune it by exploring more possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "857129d8-761c-4b75-8e26-3ff6e5eef983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:   0%|                                                                                  | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfVectorizer(max_df=0.8, min_df=10, stop_words='english', sublinear_tf=True), 2       The nymphs were collected in the stream by han...\n",
      "3       We verified both the endemic status and the di...\n",
      "4       During each cruise, specimens were sorted onbo...\n",
      "5       DNA from frozen or alcohol preserved liver or ...\n",
      "6       Specimens were collected in the Northeast of C...\n",
      "                              ...                        \n",
      "1840    5.6.21 software (Xia 2013). For COI, saturatio...\n",
      "1841    Collecting and culture of tardigrades\\nSamples...\n",
      "1842    (air temperature 13.2°C, and the weather condi...\n",
      "1843    These were assigned to H.tenuis, H.convexinota...\n",
      "1844    The description of each stage and period was b...\n",
      "Name: displayed_text, Length: 1303, dtype: object, \n",
      "      phenotype  phen_data  morph  biogeo  color_pattern  phen_proc  imaging  \\\n",
      "2             1          0      0       0              0          1        0   \n",
      "3             1          0      0       0              0          1        0   \n",
      "4             1          0      0       0              0          1        0   \n",
      "5             1          1      1       0              0          1        1   \n",
      "6             1          1      1       0              0          1        1   \n",
      "...         ...        ...    ...     ...            ...        ...      ...   \n",
      "1840          0          0      0       0              0          0        0   \n",
      "1841          1          1      0       0              0    ..., weight=None, message_clsname='Pipeline', message=None, params={ 'decision_function': {},\n",
      "  'fit': {},\n",
      "  'fit_predict': {},\n",
      "  'fit_transform': {},\n",
      "  'inverse_transform': {},\n",
      "  'partial_fit': {},\n",
      "  'predict': {},\n",
      "  'predict_log_proba': {},\n",
      "  'predict_proba': {},\n",
      "  'score': {},\n",
      "  'split': {},\n",
      "  'transform': {}})\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:  20%|██████████████                                                        | 1/5 [30:50<2:03:20, 1850.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfVectorizer(max_df=0.8, min_df=5, sublinear_tf=True), 1       Invertebrate samples\\nwere collected using a h...\n",
      "2       The nymphs were collected in the stream by han...\n",
      "4       During each cruise, specimens were sorted onbo...\n",
      "5       DNA from frozen or alcohol preserved liver or ...\n",
      "6       Specimens were collected in the Northeast of C...\n",
      "                              ...                        \n",
      "1840    5.6.21 software (Xia 2013). For COI, saturatio...\n",
      "1841    Collecting and culture of tardigrades\\nSamples...\n",
      "1842    (air temperature 13.2°C, and the weather condi...\n",
      "1843    These were assigned to H.tenuis, H.convexinota...\n",
      "1844    The description of each stage and period was b...\n",
      "Name: displayed_text, Length: 1302, dtype: object, \n",
      "      phenotype  phen_data  morph  biogeo  color_pattern  phen_proc  imaging  \\\n",
      "1             1          0      0       0              0          1        1   \n",
      "2             1          0      0       0              0          1        0   \n",
      "4             1          0      0       0              0          1        0   \n",
      "5             1          1      1       0              0          1        1   \n",
      "6             1          1      1       0              0          1        1   \n",
      "...         ...        ...    ...     ...            ...        ...      ...   \n",
      "1840          0          0      0       0              0          0        0   \n",
      "1841          1          1      0       0              0    ..., weight=None, message_clsname='Pipeline', message=None, params={ 'decision_function': {},\n",
      "  'fit': {},\n",
      "  'fit_predict': {},\n",
      "  'fit_transform': {},\n",
      "  'inverse_transform': {},\n",
      "  'partial_fit': {},\n",
      "  'predict': {},\n",
      "  'predict_log_proba': {},\n",
      "  'predict_proba': {},\n",
      "  'score': {},\n",
      "  'split': {},\n",
      "  'transform': {}})\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:  40%|███████████████████████████▏                                        | 2/5 [1:00:10<1:29:51, 1797.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfVectorizer(max_df=0.95, min_df=10, sublinear_tf=True), 1       Invertebrate samples\\nwere collected using a h...\n",
      "3       We verified both the endemic status and the di...\n",
      "4       During each cruise, specimens were sorted onbo...\n",
      "8       The species redescription and the illustration...\n",
      "9       Bootstrap support was calculated with 1000 rep...\n",
      "                              ...                        \n",
      "1840    5.6.21 software (Xia 2013). For COI, saturatio...\n",
      "1841    Collecting and culture of tardigrades\\nSamples...\n",
      "1842    (air temperature 13.2°C, and the weather condi...\n",
      "1843    These were assigned to H.tenuis, H.convexinota...\n",
      "1844    The description of each stage and period was b...\n",
      "Name: displayed_text, Length: 1303, dtype: object, \n",
      "      phenotype  phen_data  morph  biogeo  color_pattern  phen_proc  imaging  \\\n",
      "1             1          0      0       0              0          1        1   \n",
      "3             1          0      0       0              0          1        0   \n",
      "4             1          0      0       0              0          1        0   \n",
      "8             1          0      0       0              0          1        1   \n",
      "9             0          0      0       0              0          0        0   \n",
      "...         ...        ...    ...     ...            ...        ...      ...   \n",
      "1840          0          0      0       0              0          0        0   \n",
      "1841          1          1      0       0              0    ..., weight=None, message_clsname='Pipeline', message=None, params={ 'decision_function': {},\n",
      "  'fit': {},\n",
      "  'fit_predict': {},\n",
      "  'fit_transform': {},\n",
      "  'inverse_transform': {},\n",
      "  'partial_fit': {},\n",
      "  'predict': {},\n",
      "  'predict_log_proba': {},\n",
      "  'predict_proba': {},\n",
      "  'score': {},\n",
      "  'split': {},\n",
      "  'transform': {}})\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:  60%|██████████████████████████████████████████                            | 3/5 [1:30:08<59:55, 1797.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfVectorizer(max_df=0.95, min_df=10, sublinear_tf=True), 1       Invertebrate samples\\nwere collected using a h...\n",
      "2       The nymphs were collected in the stream by han...\n",
      "3       We verified both the endemic status and the di...\n",
      "4       During each cruise, specimens were sorted onbo...\n",
      "5       DNA from frozen or alcohol preserved liver or ...\n",
      "                              ...                        \n",
      "1840    5.6.21 software (Xia 2013). For COI, saturatio...\n",
      "1841    Collecting and culture of tardigrades\\nSamples...\n",
      "1842    (air temperature 13.2°C, and the weather condi...\n",
      "1843    These were assigned to H.tenuis, H.convexinota...\n",
      "1844    The description of each stage and period was b...\n",
      "Name: displayed_text, Length: 1302, dtype: object, \n",
      "      phenotype  phen_data  morph  biogeo  color_pattern  phen_proc  imaging  \\\n",
      "1             1          0      0       0              0          1        1   \n",
      "2             1          0      0       0              0          1        0   \n",
      "3             1          0      0       0              0          1        0   \n",
      "4             1          0      0       0              0          1        0   \n",
      "5             1          1      1       0              0          1        1   \n",
      "...         ...        ...    ...     ...            ...        ...      ...   \n",
      "1840          0          0      0       0              0          0        0   \n",
      "1841          1          1      0       0              0    ..., weight=None, message_clsname='Pipeline', message=None, params={ 'decision_function': {},\n",
      "  'fit': {},\n",
      "  'fit_predict': {},\n",
      "  'fit_transform': {},\n",
      "  'inverse_transform': {},\n",
      "  'partial_fit': {},\n",
      "  'predict': {},\n",
      "  'predict_log_proba': {},\n",
      "  'predict_proba': {},\n",
      "  'score': {},\n",
      "  'split': {},\n",
      "  'transform': {}})\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:  80%|████████████████████████████████████████████████████████              | 4/5 [1:59:54<29:52, 1792.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfVectorizer(max_df=0.95, min_df=5, sublinear_tf=True), 1       Invertebrate samples\\nwere collected using a h...\n",
      "2       The nymphs were collected in the stream by han...\n",
      "3       We verified both the endemic status and the di...\n",
      "5       DNA from frozen or alcohol preserved liver or ...\n",
      "6       Specimens were collected in the Northeast of C...\n",
      "                              ...                        \n",
      "1840    5.6.21 software (Xia 2013). For COI, saturatio...\n",
      "1841    Collecting and culture of tardigrades\\nSamples...\n",
      "1842    (air temperature 13.2°C, and the weather condi...\n",
      "1843    These were assigned to H.tenuis, H.convexinota...\n",
      "1844    The description of each stage and period was b...\n",
      "Name: displayed_text, Length: 1302, dtype: object, \n",
      "      phenotype  phen_data  morph  biogeo  color_pattern  phen_proc  imaging  \\\n",
      "1             1          0      0       0              0          1        1   \n",
      "2             1          0      0       0              0          1        0   \n",
      "3             1          0      0       0              0          1        0   \n",
      "5             1          1      1       0              0          1        1   \n",
      "6             1          1      1       0              0          1        1   \n",
      "...         ...        ...    ...     ...            ...        ...      ...   \n",
      "1840          0          0      0       0              0          0        0   \n",
      "1841          1          1      0       0              0    ..., weight=None, message_clsname='Pipeline', message=None, params={ 'decision_function': {},\n",
      "  'fit': {},\n",
      "  'fit_predict': {},\n",
      "  'fit_transform': {},\n",
      "  'inverse_transform': {},\n",
      "  'partial_fit': {},\n",
      "  'predict': {},\n",
      "  'predict_log_proba': {},\n",
      "  'predict_proba': {},\n",
      "  'score': {},\n",
      "  'split': {},\n",
      "  'transform': {}})\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV: 100%|██████████████████████████████████████████████████████████████████████| 5/5 [2:29:46<00:00, 1797.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# Plain TF‑IDF vectoriser\n",
    "plain_tfidf = TfidfVectorizer(\n",
    "    analyzer='word',          \n",
    "    norm='l2',\n",
    "    sublinear_tf=True         \n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('vect', plain_tfidf),\n",
    "    ('clf', OneVsRestClassifier(\n",
    "        LogisticRegression(max_iter=2000, solver='lbfgs', n_jobs=-1)\n",
    "    ))\n",
    "], memory=joblib.Memory(location=\"~/tmp/pipeline_cache\"))\n",
    "\n",
    "# Hyper‑parameter grid – “extensive but sane”\n",
    "param_grid = {\n",
    "    # TF‑IDF\n",
    "    'vect__ngram_range' : [(1,1), (1,2), (1,3), (2,2)],\n",
    "    'vect__min_df'      : [1, 2, 5, 10],\n",
    "    'vect__max_df'      : [0.8, 0.9, 0.95],\n",
    "    'vect__stop_words'  : [None, 'english'],\n",
    "\n",
    "    # Logistic‑regression\n",
    "    'clf__estimator__C'           : [0.1, 1, 10],\n",
    "    'clf__estimator__class_weight': ['balanced'],\n",
    "}\n",
    "\n",
    "# Nested CV\n",
    "tfidf_stats = cv_with_stats(pipe, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfb6a380-c37b-4433-be4e-426225405cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "with open(\"methods_paper_files/tfidf_stats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_stats, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8a41077-d3df-429f-bfed-9711576e460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen params: [('clf__estimator__C', 10), ('clf__estimator__class_weight', 'balanced'), ('vect__max_df', 0.95), ('vect__min_df', 5), ('vect__ngram_range', (1, 1)), ('vect__stop_words', None)]\n"
     ]
    }
   ],
   "source": [
    "# get best params\n",
    "\n",
    "params_per_fold = tfidf_stats['best_params']     \n",
    "scores_per_fold = tfidf_stats['fold_df']['macro_f1']\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"params\": params_per_fold,\n",
    "    \"fold_score\": scores_per_fold\n",
    "})\n",
    "\n",
    "# Convert the param dictionaries to strings so we can group them\n",
    "df[\"param_key\"] = df[\"params\"].apply(lambda d: str(sorted(d.items())))\n",
    "\n",
    "mean_scores = (df\n",
    "               .groupby(\"param_key\")[\"fold_score\"]\n",
    "               .mean()\n",
    "               .sort_values(ascending=False))\n",
    "\n",
    "best_key = mean_scores.index[0]\n",
    "best_params = eval(best_key)        # back to a dict\n",
    "print(\"Chosen params:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd23128-1796-4b7b-a4b1-07af87b5dfc1",
   "metadata": {},
   "source": [
    "# Step 3: Tune LR using the chosen tf idf configuration\n",
    "\n",
    "Now that we know which parameters are best for tf-idf, we can tune the parameters of LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0842238e-0d8d-4de5-b3d8-82b109f264b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:   0%|                                                                                  | 0/5 [00:00<?, ?it/s]C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "5 fits failed out of a total of 185.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.62799772 0.65718981 0.6493068  0.65982757 0.73503786 0.7366164\n",
      " 0.1755694  0.16459235 0.48132544 0.70808459 0.75807523 0.75271911\n",
      " 0.14234803 0.17440757 0.14350675 0.40954399 0.15205459 0.13760985\n",
      " 0.66552705 0.62260833 0.52066949 0.67969814 0.690678   0.70082602\n",
      " 0.74289316 0.7587983  0.7667712  0.73857754 0.74612234 0.75762838\n",
      " 0.67962398 0.68083318 0.69212807 0.72858223 0.74401907 0.73899696\n",
      "        nan]\n",
      "  warnings.warn(\n",
      "Outer CV:  20%|██████████████                                                        | 1/5 [36:05<2:24:22, 2165.66s/it]C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "5 fits failed out of a total of 185.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.63222499 0.66019876 0.64732342 0.6799151  0.74002893 0.73645579\n",
      " 0.14477904 0.14169644 0.48320577 0.71581857 0.75103135 0.74732138\n",
      " 0.1495108  0.14593213 0.16829323 0.42710911 0.15296458 0.14667936\n",
      " 0.66027217 0.63069686 0.51331808 0.67928031 0.69973172 0.70161502\n",
      " 0.74233233 0.75074714 0.76264463 0.73812727 0.74444316 0.7521168\n",
      " 0.68100681 0.67920454 0.69257775 0.73188951 0.74203647 0.73954869\n",
      "        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfVectorizer(max_df=0.95, min_df=5, sublinear_tf=True), 1       Invertebrate samples\\nwere collected using a h...\n",
      "2       The nymphs were collected in the stream by han...\n",
      "4       During each cruise, specimens were sorted onbo...\n",
      "5       DNA from frozen or alcohol preserved liver or ...\n",
      "6       Specimens were collected in the Northeast of C...\n",
      "                              ...                        \n",
      "1840    5.6.21 software (Xia 2013). For COI, saturatio...\n",
      "1841    Collecting and culture of tardigrades\\nSamples...\n",
      "1842    (air temperature 13.2°C, and the weather condi...\n",
      "1843    These were assigned to H.tenuis, H.convexinota...\n",
      "1844    The description of each stage and period was b...\n",
      "Name: displayed_text, Length: 1302, dtype: object, \n",
      "      phenotype  phen_data  morph  biogeo  color_pattern  phen_proc  imaging  \\\n",
      "1             1          0      0       0              0          1        1   \n",
      "2             1          0      0       0              0          1        0   \n",
      "4             1          0      0       0              0          1        0   \n",
      "5             1          1      1       0              0          1        1   \n",
      "6             1          1      1       0              0          1        1   \n",
      "...         ...        ...    ...     ...            ...        ...      ...   \n",
      "1840          0          0      0       0              0          0        0   \n",
      "1841          1          1      0       0              0    ..., weight=None, message_clsname='Pipeline', message=None, params={ 'decision_function': {},\n",
      "  'fit': {},\n",
      "  'fit_predict': {},\n",
      "  'fit_transform': {},\n",
      "  'inverse_transform': {},\n",
      "  'partial_fit': {},\n",
      "  'predict': {},\n",
      "  'predict_log_proba': {},\n",
      "  'predict_proba': {},\n",
      "  'score': {},\n",
      "  'split': {},\n",
      "  'transform': {}})\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:  40%|███████████████████████████▏                                        | 2/5 [1:11:21<1:46:48, 2136.15s/it]C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "5 fits failed out of a total of 185.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.63667041 0.65911104 0.65629497 0.68580037 0.74033246 0.73954355\n",
      " 0.1483585  0.14851061 0.47029833 0.71670868 0.75852438 0.75799068\n",
      " 0.15102447 0.16033003 0.16417751 0.43210726 0.12865295 0.15825992\n",
      " 0.67212588 0.64505832 0.51447946 0.68244244 0.68961324 0.69997783\n",
      " 0.74315684 0.75820532 0.76869382 0.74229996 0.75238053 0.75750043\n",
      " 0.68245511 0.68246132 0.69595768 0.73121788 0.74906396 0.74259408\n",
      "        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfVectorizer(max_df=0.95, min_df=5, sublinear_tf=True), 1       Invertebrate samples\\nwere collected using a h...\n",
      "3       We verified both the endemic status and the di...\n",
      "4       During each cruise, specimens were sorted onbo...\n",
      "8       The species redescription and the illustration...\n",
      "9       Bootstrap support was calculated with 1000 rep...\n",
      "                              ...                        \n",
      "1840    5.6.21 software (Xia 2013). For COI, saturatio...\n",
      "1841    Collecting and culture of tardigrades\\nSamples...\n",
      "1842    (air temperature 13.2°C, and the weather condi...\n",
      "1843    These were assigned to H.tenuis, H.convexinota...\n",
      "1844    The description of each stage and period was b...\n",
      "Name: displayed_text, Length: 1303, dtype: object, \n",
      "      phenotype  phen_data  morph  biogeo  color_pattern  phen_proc  imaging  \\\n",
      "1             1          0      0       0              0          1        1   \n",
      "3             1          0      0       0              0          1        0   \n",
      "4             1          0      0       0              0          1        0   \n",
      "8             1          0      0       0              0          1        1   \n",
      "9             0          0      0       0              0          0        0   \n",
      "...         ...        ...    ...     ...            ...        ...      ...   \n",
      "1840          0          0      0       0              0          0        0   \n",
      "1841          1          1      0       0              0    ..., weight=None, message_clsname='Pipeline', message=None, params={ 'decision_function': {},\n",
      "  'fit': {},\n",
      "  'fit_predict': {},\n",
      "  'fit_transform': {},\n",
      "  'inverse_transform': {},\n",
      "  'partial_fit': {},\n",
      "  'predict': {},\n",
      "  'predict_log_proba': {},\n",
      "  'predict_proba': {},\n",
      "  'score': {},\n",
      "  'split': {},\n",
      "  'transform': {}})\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:  60%|████████████████████████████████████████▊                           | 3/5 [1:46:31<1:10:48, 2124.43s/it]C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "5 fits failed out of a total of 185.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.6454836  0.66276986 0.65169099 0.67033725 0.73533095 0.7335616\n",
      " 0.16847682 0.12680454 0.4639205  0.70393275 0.75697457 0.75517919\n",
      " 0.16535853 0.15136459 0.16101958 0.40899086 0.16113535 0.14644443\n",
      " 0.66905735 0.63350472 0.51437819 0.67621499 0.69120797 0.69366625\n",
      " 0.74186813 0.74906833 0.76678651 0.73702603 0.74765035 0.75520697\n",
      " 0.68045851 0.679696   0.69107449 0.72686984 0.74406481 0.73875078\n",
      "        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfVectorizer(max_df=0.95, min_df=5, sublinear_tf=True), 1       Invertebrate samples\\nwere collected using a h...\n",
      "2       The nymphs were collected in the stream by han...\n",
      "3       We verified both the endemic status and the di...\n",
      "4       During each cruise, specimens were sorted onbo...\n",
      "5       DNA from frozen or alcohol preserved liver or ...\n",
      "                              ...                        \n",
      "1840    5.6.21 software (Xia 2013). For COI, saturatio...\n",
      "1841    Collecting and culture of tardigrades\\nSamples...\n",
      "1842    (air temperature 13.2°C, and the weather condi...\n",
      "1843    These were assigned to H.tenuis, H.convexinota...\n",
      "1844    The description of each stage and period was b...\n",
      "Name: displayed_text, Length: 1302, dtype: object, \n",
      "      phenotype  phen_data  morph  biogeo  color_pattern  phen_proc  imaging  \\\n",
      "1             1          0      0       0              0          1        1   \n",
      "2             1          0      0       0              0          1        0   \n",
      "3             1          0      0       0              0          1        0   \n",
      "4             1          0      0       0              0          1        0   \n",
      "5             1          1      1       0              0          1        1   \n",
      "...         ...        ...    ...     ...            ...        ...      ...   \n",
      "1840          0          0      0       0              0          0        0   \n",
      "1841          1          1      0       0              0    ..., weight=None, message_clsname='Pipeline', message=None, params={ 'decision_function': {},\n",
      "  'fit': {},\n",
      "  'fit_predict': {},\n",
      "  'fit_transform': {},\n",
      "  'inverse_transform': {},\n",
      "  'partial_fit': {},\n",
      "  'predict': {},\n",
      "  'predict_log_proba': {},\n",
      "  'predict_proba': {},\n",
      "  'score': {},\n",
      "  'split': {},\n",
      "  'transform': {}})\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Outer CV:  80%|████████████████████████████████████████████████████████              | 4/5 [2:25:43<36:54, 2214.19s/it]C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "5 fits failed out of a total of 185.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\pipeline.py\", line 660, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\conix\\.conda\\envs\\TM_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.63570434 0.6615182  0.65433095 0.67469232 0.73813347 0.73442454\n",
      " 0.17029028 0.16173752 0.48132973 0.7108154  0.75472824 0.75385946\n",
      " 0.12441335 0.16032543 0.15801967 0.40685878 0.16200475 0.14623729\n",
      " 0.6690711  0.62114608 0.48802175 0.68377228 0.69047509 0.69331722\n",
      " 0.74066005 0.74921341 0.76395057 0.73533015 0.7427534  0.75167131\n",
      " 0.68257241 0.68002026 0.6916629  0.72767021 0.74465009 0.73448507\n",
      "        nan]\n",
      "  warnings.warn(\n",
      "Outer CV: 100%|██████████████████████████████████████████████████████████████████████| 5/5 [3:05:14<00:00, 2222.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# best params for these\n",
    "plain_tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    norm='l2',\n",
    "    sublinear_tf=True,\n",
    "    max_df=0.95,          \n",
    "    min_df=5,             \n",
    "    ngram_range=(1, 1),   \n",
    "    stop_words=None       \n",
    ")\n",
    "\n",
    "lr_pipe = Pipeline([\n",
    "    ('vect', plain_tfidf),\n",
    "    ('clf', OneVsRestClassifier(\n",
    "        LogisticRegression(max_iter=2000, solver='lbfgs', n_jobs=-1)\n",
    "    ))\n",
    "], memory=joblib.Memory(location=\"~/tmp/pipeline_cache\"))\n",
    "\n",
    "\n",
    "# try two solvers\n",
    "SOLVER_SPARSE = 'saga'   \n",
    "SOLVER_DENSE  = 'lbfgs'  \n",
    "\n",
    "param_grid = [\n",
    "    # —— saga, L2 ———————————————————————————\n",
    "    {\n",
    "        'clf__estimator__solver':  [SOLVER_SPARSE],\n",
    "        'clf__estimator__penalty': ['l2'],\n",
    "        'clf__estimator__C':       [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "        'clf__estimator__class_weight': ['balanced'],\n",
    "    },\n",
    "    # —— saga, L1 ———————————————————————————\n",
    "    {\n",
    "        'clf__estimator__solver':  [SOLVER_SPARSE],\n",
    "        'clf__estimator__penalty': ['l1'],\n",
    "        'clf__estimator__C':       [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "        'clf__estimator__class_weight': ['balanced'],\n",
    "    },\n",
    "    # —— saga, elastic‑net ——————————————\n",
    "    {\n",
    "        'clf__estimator__solver':  [SOLVER_SPARSE],\n",
    "        'clf__estimator__penalty': ['elasticnet'],\n",
    "        'clf__estimator__l1_ratio': [0.1, 0.5, 0.9],\n",
    "        'clf__estimator__C':       [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "        'clf__estimator__class_weight': ['balanced'],\n",
    "    },\n",
    "    # —— lbfgs, L2 ——————————————————————————\n",
    "    {\n",
    "        'clf__estimator__solver':  [SOLVER_DENSE],\n",
    "        'clf__estimator__penalty': ['l2'],\n",
    "        'clf__estimator__C':       [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "        'clf__estimator__class_weight': ['balanced'],\n",
    "    },\n",
    "    # —— lbfgs, no regularisation ——————————\n",
    "    {\n",
    "        'clf__estimator__solver':  [SOLVER_DENSE],\n",
    "        'clf__estimator__penalty': ['None'],\n",
    "        'clf__estimator__class_weight': ['balanced'],\n",
    "    },\n",
    "]\n",
    "\n",
    "# run nested cv\n",
    "best_lr_stats = cv_with_stats(lr_pipe, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0ca4e8a-37ff-43c7-a90e-584db7421bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "with open(\"methods_paper_files/best_lr_stats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_lr_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41c522ac-e06c-4070-a4e0-e751c50575b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nested-CV macro/micro-F1 (plain tf-idf + LR grid):\n",
      "macro_f1    0.755700\n",
      "micro_f1    0.821548\n",
      "dtype: float64\n",
      "Aggregated best params: {'clf__estimator__C': 10, 'clf__estimator__class_weight': 'balanced', 'clf__estimator__l1_ratio': 0.9, 'clf__estimator__penalty': 'elasticnet', 'clf__estimator__solver': 'saga'}\n",
      "Best thresholds: [0.225  0.3125 0.3125 0.3125 0.475  0.325  0.375  0.525  0.475  0.5\n",
      " 0.3375 0.5875 0.3    0.4875 0.5125 0.6125 0.25   0.2375 0.4125 0.55\n",
      " 0.4875 0.2625 0.6875 0.375  0.55   0.3875 0.625  0.5625 0.6875 0.3625\n",
      " 0.3125 0.525  0.7    0.4375 0.6375 0.5375 0.375  0.4375]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNested-CV macro/micro-F1 (plain tf-idf + LR grid):\")\n",
    "print(best_lr_stats['mean'][['macro_f1', 'micro_f1']])\n",
    "\n",
    "best_params = best_lr_stats['best_params']\n",
    "\n",
    "agg_params = {}\n",
    "for param in best_params[0].keys():\n",
    "    # count how many times each value was chosen\n",
    "    cnt = Counter(d[param] for d in best_params)\n",
    "    # pick the most common\n",
    "    agg_params[param] = cnt.most_common(1)[0][0]\n",
    "\n",
    "print(\"Aggregated best params:\", agg_params)\n",
    "\n",
    "best_global_thresh = np.array(best_lr_stats[\"thresholds\"])\n",
    "print(\"Best thresholds:\", best_global_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a167b6f-1454-476f-8fdc-7d947cec223e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=10,\n",
       "                                                                  class_weight=&#x27;balanced&#x27;,\n",
       "                                                                  l1_ratio=0.9,\n",
       "                                                                  max_iter=20000,\n",
       "                                                                  penalty=&#x27;elasticnet&#x27;,\n",
       "                                                                  solver=&#x27;saga&#x27;)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=10,\n",
       "                                                                  class_weight=&#x27;balanced&#x27;,\n",
       "                                                                  l1_ratio=0.9,\n",
       "                                                                  max_iter=20000,\n",
       "                                                                  penalty=&#x27;elasticnet&#x27;,\n",
       "                                                                  solver=&#x27;saga&#x27;)))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>clf: OneVsRestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for clf: OneVsRestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;,\n",
       "                                                 l1_ratio=0.9, max_iter=20000,\n",
       "                                                 penalty=&#x27;elasticnet&#x27;,\n",
       "                                                 solver=&#x27;saga&#x27;))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, l1_ratio=0.9, max_iter=20000,\n",
       "                   penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, l1_ratio=0.9, max_iter=20000,\n",
       "                   penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                ('clf',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=10,\n",
       "                                                                  class_weight='balanced',\n",
       "                                                                  l1_ratio=0.9,\n",
       "                                                                  max_iter=20000,\n",
       "                                                                  penalty='elasticnet',\n",
       "                                                                  solver='saga')))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IF COMING FROM TUNING:\n",
    "\n",
    "best_params = best_lr_stats['best_params']\n",
    "agg_params  = {}\n",
    "for k in best_params[0]:\n",
    "    vals = [d[k] for d in best_params]\n",
    "    try:\n",
    "        agg_params[k] = Counter(vals).most_common(1)[0][0]\n",
    "    except TypeError:          # un‑hashable → fall back to first value\n",
    "        agg_params[k] = vals[0]\n",
    "\n",
    "# Build pipeline with exactly those params\n",
    "tfidf_params = {k.split('__', 1)[1]                 : v for k, v in agg_params.items()\n",
    "                if k.startswith('vect__')}\n",
    "lr_params    = {k.split('__', 2)[2]                 : v for k, v in agg_params.items()\n",
    "                if k.startswith('clf__estimator__')}\n",
    "\n",
    "# make sure we have a solver \n",
    "if 'solver' not in lr_params:\n",
    "    lr_params['solver'] = 'saga'        # fallback; remove if you don’t want it\n",
    "\n",
    "# build the objects\n",
    "plain_tfidf = TfidfVectorizer(**tfidf_params)\n",
    "\n",
    "logreg = LogisticRegression(max_iter=int(2e4), **lr_params)\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    ('vect', plain_tfidf),\n",
    "    ('clf',  OneVsRestClassifier(logreg))\n",
    "])\n",
    "\n",
    "# fit\n",
    "final_pipe.fit(pd.concat([X_train_raw, X_bias]),\n",
    "               pd.concat([y_train_raw,  y_bias]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d3e6582-5095-43a8-9305-5eb58e9982ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;word&#x27;,\n",
       "                                                 TfidfVectorizer(max_df=0.95,\n",
       "                                                                 min_df=5)),\n",
       "                                                (&#x27;char&#x27;,\n",
       "                                                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              5)))],\n",
       "                              transformer_weights={&#x27;char&#x27;: 1.0, &#x27;word&#x27;: 1.0})),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=10,\n",
       "                                                                  class_weight=&#x27;balanced&#x27;,\n",
       "                                                                  max_iter=1000)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;word&#x27;,\n",
       "                                                 TfidfVectorizer(max_df=0.95,\n",
       "                                                                 min_df=5)),\n",
       "                                                (&#x27;char&#x27;,\n",
       "                                                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              5)))],\n",
       "                              transformer_weights={&#x27;char&#x27;: 1.0, &#x27;word&#x27;: 1.0})),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=10,\n",
       "                                                                  class_weight=&#x27;balanced&#x27;,\n",
       "                                                                  max_iter=1000)))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>vect: FeatureUnion</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.FeatureUnion.html\">?<span>Documentation for vect: FeatureUnion</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>FeatureUnion(transformer_list=[(&#x27;word&#x27;, TfidfVectorizer(max_df=0.95, min_df=5)),\n",
       "                               (&#x27;char&#x27;,\n",
       "                                TfidfVectorizer(analyzer=&#x27;char_wb&#x27;,\n",
       "                                                ngram_range=(2, 5)))],\n",
       "             transformer_weights={&#x27;char&#x27;: 1.0, &#x27;word&#x27;: 1.0})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>word</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_df=0.95, min_df=5)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>char</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, ngram_range=(2, 5))</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>clf: OneVsRestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for clf: OneVsRestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneVsRestClassifier(estimator=LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;,\n",
       "                                                 max_iter=1000))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 FeatureUnion(transformer_list=[('word',\n",
       "                                                 TfidfVectorizer(max_df=0.95,\n",
       "                                                                 min_df=5)),\n",
       "                                                ('char',\n",
       "                                                 TfidfVectorizer(analyzer='char_wb',\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              5)))],\n",
       "                              transformer_weights={'char': 1.0, 'word': 1.0})),\n",
       "                ('clf',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(C=10,\n",
       "                                                                  class_weight='balanced',\n",
       "                                                                  max_iter=1000)))])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IF NOT COMING FROM TUNING: \n",
    "\n",
    "best_global_thresh =  [0.225 , 0.3125 ,0.3125 ,0.3125 ,0.475,  0.325 , 0.375 , 0.525 , 0.475 , 0.5,\n",
    " 0.3375 ,0.5875, 0.3    ,0.4875 ,0.5125, 0.6125, 0.25 ,  0.2375, 0.4125, 0.55,\n",
    " 0.4875, 0.2625, 0.6875, 0.375 , 0.55,   0.3875, 0.625,  0.5625, 0.6875, 0.3625,\n",
    " 0.3125 ,0.525,  0.7 ,   0.4375, 0.6375, 0.5375, 0.375,  0.4375]\n",
    "\n",
    "plain_tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    norm='l2',\n",
    "    sublinear_tf=True,\n",
    "    max_df=0.95,          \n",
    "    min_df=5,             \n",
    "    ngram_range=(1, 1),   \n",
    "    stop_words=None       \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    ('vect', plain_tfidf), \n",
    "    ('clf', OneVsRestClassifier(\n",
    "        LogisticRegression(\n",
    "            C=10,\n",
    "            class_weight='balanced',\n",
    "            max_iter=2e4,\n",
    "            solver='saga',\n",
    "            penalty = 'elasticnet',\n",
    "            l1_ratio = 0.9\n",
    "        )\n",
    "    ))\n",
    "])\n",
    "\n",
    "final_pipe.fit(\n",
    "    pd.concat([X_train_raw, X_bias]),\n",
    "    pd.concat([y_train_raw, y_bias])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64d89329-e488-4904-9bd6-82a3a4b562d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model + thresholds saved to final_lr_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "model_payload = {\n",
    "    'pipeline': final_pipe,\n",
    "    'thresholds': best_global_thresh,\n",
    "    'label_names': y_train_raw.columns.tolist()  \n",
    "}\n",
    "joblib.dump(model_payload, \"methods_paper_files/results/final_lr_model.pkl\")\n",
    "print(\"Model + thresholds saved to final_lr_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0fea9e2-60aa-4e9a-a2b4-cb57150b7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "payload = joblib.load(\"methods_paper_files/results/final_lr_model.pkl\")\n",
    "\n",
    "# unpack\n",
    "final_pipe   = payload[\"pipeline\"]\n",
    "agg_thresh   = payload[\"thresholds\"]\n",
    "label_names  = payload[\"label_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b986d1e-0b8e-4e73-823f-d26ce8a23ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to propagate the hierarchy through the classifier results\n",
    "# this at least partially captures label relations in this binary-relevance strategy\n",
    "def propagate_hierarchy(pred_df, classif):\n",
    "    \"\"\"Return a copy where every parent/cross-link label is made 1\n",
    "       if any of its children are 1.\"\"\"\n",
    "    out = pred_df.copy()\n",
    "\n",
    "    def recurse(node):\n",
    "        if isinstance(node, dict):\n",
    "            for parent, children in node.items():\n",
    "                recurse(children)\n",
    "                child_keys = []\n",
    "                for c in children:\n",
    "                    if isinstance(c, str):\n",
    "                        child_keys.append(c)\n",
    "                    elif isinstance(c, dict):\n",
    "                        child_keys.extend(c.keys())\n",
    "                if child_keys:\n",
    "                    out.loc[out[child_keys].eq(1).any(axis=1), parent] = 1\n",
    "        elif isinstance(node, list):\n",
    "            for item in node:\n",
    "                recurse(item)\n",
    "\n",
    "    recurse(classif)\n",
    "\n",
    "    # cross-links outside the hierarchical classification\n",
    "    if {'interbr_morph','gen_interbr','interbreeding'}.issubset(out):\n",
    "        mask = (out.interbr_morph==1)|(out.gen_interbr==1)\n",
    "        out.loc[mask, 'interbreeding'] = 1\n",
    "\n",
    "    if {'distance_based','distance'}.issubset(out):\n",
    "        out.loc[out.distance_based==1, 'distance'] = 1\n",
    "\n",
    "    if {'phen_pylo','phylo_sd','phylo_tree','phylogenetic'}.issubset(out):\n",
    "        mask = (out.phen_pylo==1)|(out.phylo_sd==1)|(out.phylo_tree==1)\n",
    "        out.loc[mask, 'phylogenetic'] = 1\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3ee8501-c78c-4285-85cd-7e2ca00a9a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final held-out test macro-F1: 0.7640602968387167\n",
      "Final held-out test micro-F1: 0.8324240062353858\n"
     ]
    }
   ],
   "source": [
    "# Compute raw probabilities on X_test\n",
    "proba_test = final_pipe.predict_proba(X_test) \n",
    "\n",
    "# Binarize using agg_thresh (one cutoff per column)\n",
    "y_test_hat = (proba_test >= np.array(agg_thresh)).astype(int)\n",
    "\n",
    "# Build DataFrame, enforce hierarchy, and align columns\n",
    "test_df = pd.DataFrame(y_test_hat, columns=y_test.columns, index=X_test.index)\n",
    "test_df = propagate_hierarchy(test_df, classif).fillna(0).astype(int)\n",
    "test_df = test_df.reindex(columns=y_test.columns, fill_value=0)\n",
    "\n",
    "# Compute metrics\n",
    "final_metrics = fold_metrics(y_test, test_df.values)\n",
    "print(\"Final held-out test macro-F1:\", final_metrics['macro_f1'])\n",
    "print(\"Final held-out test micro-F1:\", final_metrics['micro_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3cba148-9c28-49e7-af21-da787f9ee1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenotype_logit</th>\n",
       "      <th>phen_data_logit</th>\n",
       "      <th>morph_logit</th>\n",
       "      <th>biogeo_logit</th>\n",
       "      <th>color_pattern_logit</th>\n",
       "      <th>phen_proc_logit</th>\n",
       "      <th>imaging_logit</th>\n",
       "      <th>quant_morph_logit</th>\n",
       "      <th>storage_logit</th>\n",
       "      <th>sampling_logit</th>\n",
       "      <th>...</th>\n",
       "      <th>phen_pylo</th>\n",
       "      <th>distance_based</th>\n",
       "      <th>acoustic</th>\n",
       "      <th>phylo_sd</th>\n",
       "      <th>interbreeding</th>\n",
       "      <th>specimen_storage_loc</th>\n",
       "      <th>abbrev_terms</th>\n",
       "      <th>id</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>displayed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996033</td>\n",
       "      <td>0.984249</td>\n",
       "      <td>0.977340</td>\n",
       "      <td>0.127748</td>\n",
       "      <td>0.079911</td>\n",
       "      <td>0.989590</td>\n",
       "      <td>0.959326</td>\n",
       "      <td>0.853821</td>\n",
       "      <td>0.235568</td>\n",
       "      <td>0.938342</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>./Corpus/EJT/10_5852_ejt_2021_735_1243.json_0</td>\n",
       "      <td>./Corpus/EJT/10_5852_ejt_2021_735_1243</td>\n",
       "      <td>The material examined was collected in fragmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.958663</td>\n",
       "      <td>0.847289</td>\n",
       "      <td>0.629694</td>\n",
       "      <td>0.113914</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.919240</td>\n",
       "      <td>0.625631</td>\n",
       "      <td>0.107309</td>\n",
       "      <td>0.454085</td>\n",
       "      <td>0.304208</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>./Corpus/Zootaxa/4/3/zootaxa_4312_3_5.json_0</td>\n",
       "      <td>./Corpus/Zootaxa/4/3/zootaxa_4312_3_5</td>\n",
       "      <td>Redescription is based on freshly collected to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997683</td>\n",
       "      <td>0.514083</td>\n",
       "      <td>0.329476</td>\n",
       "      <td>0.827798</td>\n",
       "      <td>0.059827</td>\n",
       "      <td>0.997679</td>\n",
       "      <td>0.279543</td>\n",
       "      <td>0.281173</td>\n",
       "      <td>0.997169</td>\n",
       "      <td>0.997751</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>./Corpus/Zootaxa/4/3/zootaxa_4312_3_3.json_0</td>\n",
       "      <td>./Corpus/Zootaxa/4/3/zootaxa_4312_3_3</td>\n",
       "      <td>Specimens were collected during field surveys ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.931685</td>\n",
       "      <td>0.938375</td>\n",
       "      <td>0.938753</td>\n",
       "      <td>0.344281</td>\n",
       "      <td>0.127859</td>\n",
       "      <td>0.229098</td>\n",
       "      <td>0.110262</td>\n",
       "      <td>0.147350</td>\n",
       "      <td>0.034864</td>\n",
       "      <td>0.125227</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./Corpus/EJT/10_5852_ejt_2021_771_1503.json_2</td>\n",
       "      <td>./Corpus/EJT/10_5852_ejt_2021_771_1503</td>\n",
       "      <td>European Journal of Taxonomy 771: 1–79 (2021)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.921157</td>\n",
       "      <td>0.160630</td>\n",
       "      <td>0.109707</td>\n",
       "      <td>0.017274</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.963469</td>\n",
       "      <td>0.983961</td>\n",
       "      <td>0.022437</td>\n",
       "      <td>0.870971</td>\n",
       "      <td>0.387865</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>./Corpus/Zootaxa/3/7/zootaxa_3785_4_6.json_0</td>\n",
       "      <td>./Corpus/Zootaxa/3/7/zootaxa_3785_4_6</td>\n",
       "      <td>Nematodes were\\nextracted using the tray metho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   phenotype_logit  phen_data_logit  morph_logit  biogeo_logit  \\\n",
       "0         0.996033         0.984249     0.977340      0.127748   \n",
       "1         0.958663         0.847289     0.629694      0.113914   \n",
       "2         0.997683         0.514083     0.329476      0.827798   \n",
       "3         0.931685         0.938375     0.938753      0.344281   \n",
       "4         0.921157         0.160630     0.109707      0.017274   \n",
       "\n",
       "   color_pattern_logit  phen_proc_logit  imaging_logit  quant_morph_logit  \\\n",
       "0             0.079911         0.989590       0.959326           0.853821   \n",
       "1             0.006551         0.919240       0.625631           0.107309   \n",
       "2             0.059827         0.997679       0.279543           0.281173   \n",
       "3             0.127859         0.229098       0.110262           0.147350   \n",
       "4             0.005713         0.963469       0.983961           0.022437   \n",
       "\n",
       "   storage_logit  sampling_logit  ...  phen_pylo  distance_based  acoustic  \\\n",
       "0       0.235568        0.938342  ...          0               0         0   \n",
       "1       0.454085        0.304208  ...          0               0         0   \n",
       "2       0.997169        0.997751  ...          0               0         0   \n",
       "3       0.034864        0.125227  ...          0               0         0   \n",
       "4       0.870971        0.387865  ...          0               0         0   \n",
       "\n",
       "   phylo_sd  interbreeding  specimen_storage_loc  abbrev_terms  \\\n",
       "0         0              0                     0             1   \n",
       "1         0              0                     0             1   \n",
       "2         0              0                     1             0   \n",
       "3         0              0                     0             0   \n",
       "4         0              0                     0             0   \n",
       "\n",
       "                                              id  \\\n",
       "0  ./Corpus/EJT/10_5852_ejt_2021_735_1243.json_0   \n",
       "1   ./Corpus/Zootaxa/4/3/zootaxa_4312_3_5.json_0   \n",
       "2   ./Corpus/Zootaxa/4/3/zootaxa_4312_3_3.json_0   \n",
       "3  ./Corpus/EJT/10_5852_ejt_2021_771_1503.json_2   \n",
       "4   ./Corpus/Zootaxa/3/7/zootaxa_3785_4_6.json_0   \n",
       "\n",
       "                                 paper_id  \\\n",
       "0  ./Corpus/EJT/10_5852_ejt_2021_735_1243   \n",
       "1   ./Corpus/Zootaxa/4/3/zootaxa_4312_3_5   \n",
       "2   ./Corpus/Zootaxa/4/3/zootaxa_4312_3_3   \n",
       "3  ./Corpus/EJT/10_5852_ejt_2021_771_1503   \n",
       "4   ./Corpus/Zootaxa/3/7/zootaxa_3785_4_6   \n",
       "\n",
       "                                      displayed_text  \n",
       "0  The material examined was collected in fragmen...  \n",
       "1  Redescription is based on freshly collected to...  \n",
       "2  Specimens were collected during field surveys ...  \n",
       "3  European Journal of Taxonomy 771: 1–79 (2021)\\...  \n",
       "4  Nematodes were\\nextracted using the tray metho...  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the data to analyze somewhere else\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "logit_df = pd.DataFrame(proba_test, columns = [f\"{i}_logit\" for i in cats])\n",
    "label_df = test_df\n",
    "id_df = df.iloc[test_idx][[\"id\",\"paper_id\",\"displayed_text\"]].reset_index(drop=True)\n",
    "\n",
    "lr_df = logit_df.join(label_df, how='inner')\n",
    "lr_df = lr_df.join(id_df, how='inner')\n",
    "df_true = df.iloc[test_idx]\n",
    "\n",
    "with open(\"methods_paper_files/results/lr_results_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lr_df, f)\n",
    "\n",
    "with open(\"methods_paper_files/results/df_true.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df_true, f)\n",
    "\n",
    "print(lr_df.shape)\n",
    "lr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c7c872e-055c-4383-9738-1726622c718a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
